{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeFCqpBEj75VuJMWRNLRua",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lapaniku/generative-sentiment/blob/main/evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "f-tAp-GBf63n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1e26dbf-1bb2-4f3c-f385-a5bd098b0bdf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('regen_valid.json', <http.client.HTTPMessage at 0x7d5f01ef9c00>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve(\"https://gist.githubusercontent.com/lapaniku/697a9f205d2b06fd10213fff28bb7fb2/raw/216da915b5bb3129cf9e708bf0b220287030f6ef/regen_valid.json\", \"regen_valid.json\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"regen_valid.json\", \"r\") as f:\n",
        "  data = json.load(f)\n",
        "\n",
        "  print(f\"Validation sample size: {len(data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXkMDqS8cBA9",
        "outputId": "3f48eafd-7ce5-43f5-a6d5-7dfed798f946"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation sample size: 464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_score_to_sentiment(label: int) -> str:\n",
        "    return [\"Strong Negative\", \"Mild Negative\", \"Neutral\", \"Mild Positive\", \"Strong Positive\"][label]"
      ],
      "metadata": {
        "id": "1C3_ygif6S62"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"alapanik/blair-roberta-base-generative-sentiment\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"alapanik/blair-roberta-base-generative-sentiment\")\n",
        "\n",
        "sentences = [item[\"ticket\"] for item in data]\n",
        "\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "duration = time.time() - start\n",
        "print(f\"Inference duration per sentence in a batch mode: {duration/len(sentences)}\")\n",
        "\n",
        "predicted = torch.argmax(outputs.logits, dim=1)\n",
        "gt = [item[\"output\"] for item in data]\n",
        "predicted_labels = [translate_score_to_sentiment(label) for label in predicted]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po-Pf1ryig5r",
        "outputId": "4686ce2b-4730-4d9a-b604-8aa367b06179"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference duration per sentence in a batch mode: 0.3007255458626254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "precision_macro = precision_score(gt, predicted_labels, average='macro', zero_division=0)\n",
        "recall_macro = recall_score(gt, predicted_labels, average='macro', zero_division=0)\n",
        "precision_micro = precision_score(gt, predicted_labels, average='micro', zero_division=0)\n",
        "recall_micro = recall_score(gt, predicted_labels, average='micro', zero_division=0)\n",
        "print(f\"Precision macro: {precision_macro:.2f}\")\n",
        "print(f\"Precision micro: {precision_micro:.2f}\")\n",
        "print(f\"Recall macro: {recall_macro:.2f}\")\n",
        "print(f\"Recall micro: {recall_micro:.2f}\")\n"
      ],
      "metadata": {
        "id": "PlBPja7W7Mf-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c31f2b15-0769-458c-cbab-2d8e3cdf25bc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision macro: 0.81\n",
            "Precision micro: 0.82\n",
            "Recall macro: 0.79\n",
            "Recall micro: 0.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(gt, predicted_labels).tolist()"
      ],
      "metadata": {
        "id": "yc9gp-rz-Qr9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b50b59b2-e5bf-4ee9-c5ac-c525dfc6f7eb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[115, 1, 13, 11, 0],\n",
              " [3, 33, 6, 0, 8],\n",
              " [18, 5, 52, 1, 0],\n",
              " [14, 0, 0, 53, 0],\n",
              " [0, 3, 0, 0, 128]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix higlights the problem of spearating \"Strong Negative\" and \"Neutral\" cases which might be something with generated data and requires additional attention. The next step for improvement is to figure out why Mild Negative is sometimes missed with Positive label. I don't think it requires some model fine-tuning but rather careful working with data."
      ],
      "metadata": {
        "id": "YukYt5ete3qF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "39w2tAaDewDp"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}