{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e63d090-1dfa-46c0-9535-4ab1f394109a",
   "metadata": {},
   "source": [
    "## Sample ticket extraction\n",
    "\n",
    "It's not easy to find some reference dataset with 5 sentiment labels as requested so I picked Amazon reviews as a source of seed examples for data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b4935d3-9c40-473b-8efd-c674f6e8124e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('amazon_reviews.csv', <http.client.HTTPMessage at 0x7f145f0f9f90>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://huggingface.co/datasets/hugginglearners/amazon-reviews-sentiment-analysis/resolve/main/amazon_reviews.csv?download=true\", \"amazon_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94c6d637-d6c8-4895-8596-6cac2f815ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reviews = pd.read_csv(\"amazon_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76265bea-e318-4126-9bac-d2811db79042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82/1479949678.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  seed_selection_df = reviews.groupby('overall', group_keys=False).apply(lambda x: x.sample(min(len(x), SAMPLES_PER_SCORE)))\n"
     ]
    }
   ],
   "source": [
    "SAMPLES_PER_SCORE = 10\n",
    "seed_selection_df = reviews.groupby('overall', group_keys=False).apply(lambda x: x.sample(min(len(x), SAMPLES_PER_SCORE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb16919-aa4f-4671-b832-e6ad4b04994e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>overall</th>\n",
       "      <th>day_diff</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>total_vote</th>\n",
       "      <th>score_pos_neg_diff</th>\n",
       "      <th>score_average_rating</th>\n",
       "      <th>wilson_lower_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2465.440000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>444.920000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.025012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1281.044156</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>244.196378</td>\n",
       "      <td>0.494872</td>\n",
       "      <td>0.481918</td>\n",
       "      <td>0.878078</td>\n",
       "      <td>0.428095</td>\n",
       "      <td>0.268868</td>\n",
       "      <td>0.067668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>109.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1439.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>311.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2543.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3354.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>615.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4855.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>941.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.342380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0    overall    day_diff  helpful_yes  helpful_no  \\\n",
       "count    50.000000  50.000000   50.000000    50.000000   50.000000   \n",
       "mean   2465.440000   3.000000  444.920000     0.200000    0.180000   \n",
       "std    1281.044156   1.428571  244.196378     0.494872    0.481918   \n",
       "min     109.000000   1.000000    2.000000     0.000000    0.000000   \n",
       "25%    1439.500000   2.000000  311.000000     0.000000    0.000000   \n",
       "50%    2543.000000   3.000000  439.000000     0.000000    0.000000   \n",
       "75%    3354.500000   4.000000  615.750000     0.000000    0.000000   \n",
       "max    4855.000000   5.000000  941.000000     2.000000    2.000000   \n",
       "\n",
       "       total_vote  score_pos_neg_diff  score_average_rating  \\\n",
       "count   50.000000           50.000000             50.000000   \n",
       "mean     0.380000            0.020000              0.106667   \n",
       "std      0.878078            0.428095              0.268868   \n",
       "min      0.000000           -1.000000              0.000000   \n",
       "25%      0.000000            0.000000              0.000000   \n",
       "50%      0.000000            0.000000              0.000000   \n",
       "75%      0.000000            0.000000              0.000000   \n",
       "max      4.000000            2.000000              1.000000   \n",
       "\n",
       "       wilson_lower_bound  \n",
       "count           50.000000  \n",
       "mean             0.025012  \n",
       "std              0.067668  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              0.000000  \n",
       "max              0.342380  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_selection_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c8c0f3d-fc0f-42c0-bc80-d41340ae74e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>day_diff</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>total_vote</th>\n",
       "      <th>score_pos_neg_diff</th>\n",
       "      <th>score_average_rating</th>\n",
       "      <th>wilson_lower_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>1699</td>\n",
       "      <td>froemer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I've requested a replacement, so I'll update t...</td>\n",
       "      <td>2014-01-18</td>\n",
       "      <td>324</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3031</th>\n",
       "      <td>3031</td>\n",
       "      <td>matt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bought it, installed it in my Droid RazrM neve...</td>\n",
       "      <td>2013-04-24</td>\n",
       "      <td>593</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>3111</td>\n",
       "      <td>Mercury</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I got this card only a few months ago, used it...</td>\n",
       "      <td>2014-09-07</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>1593</td>\n",
       "      <td>Eric Redman</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Could not figure out why this card crashed mul...</td>\n",
       "      <td>2012-12-14</td>\n",
       "      <td>724</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.061492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>2510</td>\n",
       "      <td>J. Parnell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>After I put this card in my new S4, my camera ...</td>\n",
       "      <td>2013-05-28</td>\n",
       "      <td>559</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 reviewerName  overall  \\\n",
       "1699        1699      froemer      1.0   \n",
       "3031        3031         matt      1.0   \n",
       "3111        3111      Mercury      1.0   \n",
       "1593        1593  Eric Redman      1.0   \n",
       "2510        2510   J. Parnell      1.0   \n",
       "\n",
       "                                             reviewText  reviewTime  day_diff  \\\n",
       "1699  I've requested a replacement, so I'll update t...  2014-01-18       324   \n",
       "3031  Bought it, installed it in my Droid RazrM neve...  2013-04-24       593   \n",
       "3111  I got this card only a few months ago, used it...  2014-09-07        92   \n",
       "1593  Could not figure out why this card crashed mul...  2012-12-14       724   \n",
       "2510  After I put this card in my new S4, my camera ...  2013-05-28       559   \n",
       "\n",
       "      helpful_yes  helpful_no  total_vote  score_pos_neg_diff  \\\n",
       "1699            0           0           0                   0   \n",
       "3031            0           0           0                   0   \n",
       "3111            1           0           1                   1   \n",
       "1593            1           2           3                  -1   \n",
       "2510            0           0           0                   0   \n",
       "\n",
       "      score_average_rating  wilson_lower_bound  \n",
       "1699              0.000000            0.000000  \n",
       "3031              0.000000            0.000000  \n",
       "3111              1.000000            0.206549  \n",
       "1593              0.333333            0.061492  \n",
       "2510              0.000000            0.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_selection_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7883a0e-1a0f-41a6-8a28-d024ddbfd152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_score_to_sentiment(score: int) -> str:\n",
    "    normalized_score = int(score)-1\n",
    "    if normalized_score < 5:\n",
    "        return [\"Strong Negative\", \"Mild Negative\", \"Neutral\", \"Mild Positive\", \"Strong Positive\"][normalized_score]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d9e14d-f10f-4083-9899-2f62cf092f84",
   "metadata": {},
   "source": [
    "## Seed tasks\n",
    "\n",
    "For the next step of ticket generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62ba787d-3cae-4192-9897-08100703fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "instances = []\n",
    "for i, row in seed_selection_df.iterrows():\n",
    "    instances.append({\n",
    "        \"id\": f\"seed_task_{i}\", \n",
    "        \"name\": \"sentiment_analysis\", \n",
    "        \"ticket\": row[\"reviewText\"], \n",
    "        \"instances\": [\n",
    "            {\n",
    "                \"input\": \"\", \n",
    "                \"output\": translate_score_to_sentiment(row[\"overall\"])\n",
    "            }\n",
    "        ],\n",
    "        \"is_classification\": False\n",
    "    })\n",
    "\n",
    "with open(\"./stanford_alpaca/seed_tasks.jsonl\", \"w\") as outfile:\n",
    "    for instance in instances:\n",
    "        json.dump(instance, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "701c5fdd-fa3b-4086-baf6-b4d4d48dad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "if not os.environ[\"OPENAI_API_KEY\"]:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a278e454-c85a-4bb4-a74e-007d98693ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/stanford_alpaca\n"
     ]
    }
   ],
   "source": [
    "%cd stanford_alpaca "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a7e1d-5f51-4726-b05a-c9c4c5ef141b",
   "metadata": {},
   "source": [
    "## Data generation\n",
    "\n",
    "For generation purposes I used [Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca) project which aims to train LLaMa on instructions generated by OpenAI. It can resume process, support multi-processing for de-duplication, how many requests are sent in a row. In my view great tool for the purpose. I know I might be expected to use Langchain for that purpose, but since I used this tool before and time is limited I prefered something that I can run fast.\n",
    "\n",
    "Related code can be found in the `./stanford_alpaca` folder in this project.\n",
    "\n",
    "Using seed tasks created above and several modifications:\n",
    "- to support recent OpenAI API\n",
    "- convert instruction generation to ticket generation by modifying prompt and related keywords\n",
    "it can effectively orchestrate instruction generation with the final amount of items close to the requested number.\n",
    "\n",
    "For the purpose of de-duplication it uses [Rouge Score](https://en.wikipedia.org/wiki/ROUGE_(metric)) which is the reasonable way to filter out diplicates. In this specific case longest common subsequence is calculated. If new ticket hits a score > 0.7 to some stored ticket then it is not saved. \n",
    "\n",
    "Prompts are shipped with maximum temperature of 1.0 which requires some result investigation but due to a limited time I've skipped it here and take output as is.\n",
    "\n",
    "Here is the prompt example:\n",
    "```\n",
    "You are asked to come up with a set of 20 diverse customer tickets. These customer tickets will be given to a GPT model and we will evaluate the GPT model for completing the customer sentiment.\n",
    "\n",
    "Here are the requirements:\n",
    "1. Try not to repeat the product for each ticket to maximize diversity.\n",
    "2. The language used for the ticket also should be diverse. For example, you should combine short and long tickets.\n",
    "3. The ticket should be in English.\n",
    "4. The output should be an appropriate sentiment of the customer ticket. Make sure the output is in the following list of options: \"Strong Negative\", \"Mild Negative\", \"Neutral\", \"Mild Positive\", \"Strong Positive\".\n",
    "\n",
    "List of 20 tickets:\n",
    "###\n",
    "1. Ticket: SanDisk Ultra 32 GB MicroSDHC C10/UHS1 Memory Card with Adapter...SanDisk Ultra 32 GB MicroSDHC C10/UHS1 Memory Card with Adapter...Works fine.\n",
    "1. Input:\n",
    "<noinput>\n",
    "1. Output:\n",
    "Mild Positive\n",
    "###\n",
    "2. Ticket: Pictures were bright and sharp and download from the camera to the card very quickly. If you have a better quality camera this is a great card\n",
    "2. Input:\n",
    "<noinput>\n",
    "2. Output:\n",
    "Strong Positive\n",
    "###\n",
    "3. Ticket: Spent over $50 and the thing came fast and didn't work. Neither my computer nor my phone could read it or format it. I have had plenty of memory cards, so I know to unmount it with software. Odds are yours will be fine, mine sucked,\n",
    "3. Input:\n",
    "<noinput>\n",
    "3. Output:\n",
    "Strong Negative\n",
    "###\n",
    "4. Ticket:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1742a4c6-d420-4ee9-9c03-137a91539b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 50 human-written seed instructions\n",
      "Loaded 604 machine-generated instructions\n",
      "Sending OpenAI request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]\n",
      "prompt_batches:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches: 100%|██████████| 1/1 [00:04<00:00,  4.26s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received response in 4.258951187133789\n",
      "Request 1 took 4.26s, processing took 0.00s\n",
      "Generated 0 instructions, kept 0 instructions\n",
      "Sending OpenAI request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "prompt_batches:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "prompt_batches: 100%|██████████| 1/1 [00:07<00:00,  7.39s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received response in 7.393707513809204\n",
      "Request 2 took 7.39s, processing took 1.46s\n",
      "Generated 14 instructions, kept 14 instructions\n",
      "Sending OpenAI request\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 617/10000 [00:13<03:36, 43.26it/s]\n",
      "  6%|▌         | 618/10000 [00:30<03:36, 43.26it/s]WARNING:root:OpenAIError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-xVCrgQBkdKET4yZKlcm8kONE on requests per day (RPD): Limit 200, Used 200, Requested 1. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}.\n",
      "WARNING:root:Hit request rate limit; retrying...\n",
      "prompt_batches:   0%|          | 0/1 [00:33<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jovyan/work/stanford_alpaca/utils.py\", line 115, in openai_completion\n",
      "    completion_batch = client.chat.completions.create(messages=messages, **shared_kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/openai/resources/chat/completions.py\", line 668, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/openai/_base_client.py\", line 1260, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/openai/_base_client.py\", line 937, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/openai/_base_client.py\", line 1026, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/openai/_base_client.py\", line 1075, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/openai/_base_client.py\", line 1026, in _request\n",
      "    return self._retry_request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/openai/_base_client.py\", line 1075, in _retry_request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/openai/_base_client.py\", line 1041, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-xVCrgQBkdKET4yZKlcm8kONE on requests per day (RPD): Limit 200, Used 200, Requested 1. Please try again in 7m12s. Visit https://platform.openai.com/account/rate-limits to learn more. You can increase your rate limit by adding a payment method to your account at https://platform.openai.com/account/billing.', 'type': 'requests', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/jovyan/work/stanford_alpaca/generate_instruction.py\", line 219, in <module>\n",
      "    fire.Fire(main)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/fire/core.py\", line 143, in Fire\n",
      "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/fire/core.py\", line 477, in _Fire\n",
      "    component, remaining_args = _CallAndUpdateTrace(\n",
      "                                ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/fire/core.py\", line 693, in _CallAndUpdateTrace\n",
      "    component = fn(*varargs, **kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/work/stanford_alpaca/generate_instruction.py\", line 215, in main\n",
      "    globals()[task](**kwargs)\n",
      "  File \"/home/jovyan/work/stanford_alpaca/generate_instruction.py\", line 168, in generate_instruction_following_data\n",
      "    results = utils.openai_completion(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jovyan/work/stanford_alpaca/utils.py\", line 129, in openai_completion\n",
      "    time.sleep(sleep_time)  # Annoying rate limit on requests.\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  6%|▌         | 618/10000 [00:46<11:49, 13.22it/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -m generate_instruction generate_instruction_following_data \\\n",
    "  --output_dir ./ \\\n",
    "  --num_instructions_to_generate 10000 \\\n",
    "  --model_name=\"gpt-4o-mini\" \\\n",
    "  --request_batch_size=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab0835f-3bbb-48a5-be27-5fe886fcdf7e",
   "metadata": {},
   "source": [
    "## Splitting generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1438e42-13c5-4895-a624-9616a680af70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1855\n",
      "Validation size: 464\n"
     ]
    }
   ],
   "source": [
    "SPLIT_SIZE = 0.8\n",
    "all_tickets = json.load(open(\"regen.json\", \"r\"))\n",
    "bound = int(len(all_tickets)*SPLIT_SIZE)\n",
    "regen_train = all_tickets[:bound]\n",
    "print(f\"Train size: {len(regen_train)}\")\n",
    "regen_valid = all_tickets[bound:]\n",
    "print(f\"Validation size: {len(regen_valid)}\")\n",
    "json.dump(regen_train, open(\"regen_train.json\", \"w\"))\n",
    "json.dump(regen_valid, open(\"regen_valid.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa458b8e-7bf0-4f46-9e2f-fa4e17fbb42b",
   "metadata": {},
   "source": [
    "Unfortunately I wasn't able to produce 10000 samples as intended. The first run gave me 1007 samples which I reserved for training and the second run produced 693 before I hit rate limit. Second result I reserved for validation. I could rebalance later depending on the training results, but they were satisfying in this exact scenario so I keep it as is."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
